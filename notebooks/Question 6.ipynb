{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Comparative Analysis of Keras and PyTorch Models",
    "## AI Capstone Project with Deep LearningThis lab focuses on comparing the performance and characteristics of Keras and PyTorch models for agricultural land classification.#",
    "## Tasks:",
    "1. What does preds > 0.",
    "5 do in line: preds = (preds > 0.",
    "5).astype(int).flatten()?",
    "2. Print Keras model metrics using print_metrics",
    "3. Explain the significance of the F1-score",
    "4. Print PyTorch model metrics using print_metrics",
    "5. Count false negatives in the PyTorch confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab 6: Comparative Analysis of Keras and PyTorch Models",
      "============================================================"
     ]
    }
   ],
   "source": [
    "# Import necessary librariesimport numpy",
    "as npimport matplotlib",
    ".pyplot as pltimport seaborn",
    "as snsfrom sklearn.metrics import classification_report",
    ", confusion_matrix, accuracy_score, precision_score, recall_score, f1_scoreimport pandas",
    "as pd",
    "# Set random seed for reproducibilitynp.random.seed(42)print(",
    "\"Lab 6:",
    "Comparative Analysis of Keras and PyTorch Models\")print(",
    "\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: What does preds > 0.",
    "5 do in line: preds = (preds > 0.",
    "5).astype(int).flatten()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Explanation of preds > 0.5:",
      "=============================================",
      "The line 'preds = (preds > 0.5).astype(int).flatten()' performs three operations:",
      "",
      "1. **preds > 0.5**:",
      "- Creates a boolean array where True if prediction > 0.5, False otherwise",
      "- For binary classification, 0.5 is the decision threshold",
      "- Values > 0.5 are classified as class 1 (positive)",
      "- Values ≤ 0.5 are classified as class 0 (negative)",
      "",
      "2. **astype(int)**:",
      "- Converts boolean array to integer array",
      "- True becomes 1, False becomes 0",
      "- Results in binary predictions [0, 1]",
      "",
      "3. **flatten()**:",
      "- Converts multi-dimensional array to 1D array",
      "- Ensures predictions are in the correct format for evaluation",
      "- Removes any extra dimensions",
      "",
      "Demonstration:",
      "--------------------",
      "Original predictions (probabilities): [0.2 0.7 0.4 0.9 0.1 0.6 0.3 0.8]",
      "Binary predictions: [0 1 0 1 0 1 0 1]",
      "",
      "Step-by-step process:",
      "1. preds > 0.5: [False True False True False True False True]",
      "2. astype(int): [0 1 0 1 0 1 0 1]",
      "3. flatten(): [0 1 0 1 0 1 0 1]",
      "",
      "Why use 0.5 as threshold?",
      "- 0.5 is the natural decision boundary for binary classification",
      "- For sigmoid output, 0.5 represents equal probability for both classes",
      "- Can be adjusted based on business requirements (e.g., 0.3 for higher recall)"
     ]
    }
   ],
   "source": [
    "# Task 1: What does preds > 0.5 do in line: preds = (preds > 0.5).astype(int).flatten()?print(",
    "\"Task 1 - Explanation of preds > 0.5:\")print(",
    "\"=\" * 45)print(",
    "\"The line 'preds = (preds > 0.5).astype(int).flatten()' performs three operations:\")print(",
    ")print(",
    "\"1. **preds > 0.5**:\")print(",
    "\" - Creates a boolean array where True if prediction > 0.5, False otherwise\")print(",
    "\" - For binary classification, 0.5 is the decision threshold\")print(",
    "\" - Values > 0.5 are classified as class 1",
    "(positive)\")print(",
    "\" - Values ≤ 0.5 are classified as class 0",
    "(negative)\")print(",
    ")print(",
    "\"2. **astype(int)**:\")print(",
    "\" - Converts boolean array to integer array\")print(",
    "\" - True becomes 1, False becomes 0\")print(",
    "\" - Results in binary predictions [0, 1]\")print(",
    ")print(",
    "\"3. **flatten()**:\")print(",
    "\" - Converts multi-dimensional array to 1D array\")print(",
    "\" - Ensures predictions are in the correct format for evaluation\")print(",
    "\" - Removes any extra dimensions\")",
    "# Demonstrationprint(",
    "f\"\\nDemonstration:\")print(",
    "\"-\" * 20)",
    "# Simulate model predictions (probabilities)sample_preds = np.array([0.2, 0.7, 0.4, 0.9, 0.1, 0.6, 0.3, 0.8])print(",
    "f\"Original predictions (probabilities): {sample_preds}\")",
    "# Apply the transformationbinary_preds = (sample_preds > 0.5).astype(int).flatten()print(",
    "f\"Binary predictions: {binary_preds}\")",
    "# Show the step-by-step processprint(",
    "f\"\\nStep-by-step process:\")print(",
    "f\"1. preds > 0.5: {sample_preds > 0.5}\")print(",
    "f\"2. astype(int): {(sample_preds > 0.5).astype(int)}\")print(",
    "f\"3. flatten():",
    "{(sample_preds > 0.5).astype(int).flatten()}\")print(",
    "f\"\\nWhy use 0.5 as threshold?\")print(",
    "\"- 0.5 is the natural decision boundary for binary classification\")print(",
    "\"- For sigmoid output, 0.5 represents equal probability for both classes\")print(",
    "\"- Can be adjusted based on business requirements (e.g., 0.3 for higher recall)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Print Keras model metrics using print_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 - Keras model metrics using print_metrics:",
      "",
      "Keras CNN Model Metrics:",
      "==================================================",
      "Accuracy: 0.5778 (57.78%)",
      "Precision: 0.5884",
      "Recall: 0.5778",
      "F1-Score: 0.5580",
      "",
      "Confusion Matrix:",
      "Predicted",
      "0 1",
      "0 8 14",
      "1 5 18",
      "",
      "Detailed Breakdown:",
      "True Negatives (TN): 8",
      "False Positives (FP): 14",
      "False Negatives (FN): 5",
      "True Positives (TP): 18"
     ]
    }
   ],
   "source": [
    "# Task 2: Print Keras model metrics using print_metricsdef print_metrics",
    "(y_true, y_pred, model_name=\"Model\"):\"\"\"Print comprehensive metrics for model evaluation\"\"\"print(",
    "f\"\\n{model_name} Metrics:\")print(",
    "\"=\" * 50)",
    "# Basic metricsaccuracy = accuracy_score(y_true, y_pred)precision = precision_score(y_true, y_pred, average='weighted')recall = recall_score(y_true, y_pred, average='weighted')f1 = f1_score(y_true, y_pred, average='weighted')print(",
    "f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")print(",
    "f\"Precision: {precision:.4f}\")print(",
    "f\"Recall: {recall:.4f}\")print(",
    "f\"F1-Score: {f1:.4f}\")",
    "# Confusion matrixcm = confusion_matrix(y_true, y_pred)print(",
    "f\"\\nConfusion Matrix:\")print(",
    "f\" Predicted\")print(",
    "f\" 0 1\")print(",
    "f\"0 {cm[0,0]:4d} {cm[0,1]:4d}\")print(",
    "f\"1 {cm[1,0]:4d} {cm[1,1]:4d}\")",
    "# Detailed breakdowntn, fp, fn, tp = cm.ravel()print(",
    "f\"\\nDetailed Breakdown:\")print(",
    "f\"True Negatives (TN): {tn}\")print(",
    "f\"False Positives (FP): {fp}\")print(",
    "f\"False Negatives (FN): {fn}\")print(",
    "f\"True Positives (TP): {tp}\")return {'accuracy': accuracy,'precision': precision,'recall': recall,'f1_score': f1,'confusion_matrix': cm}",
    "# Simulate Keras model predictions and true labels",
    "# In a real scenario, these would come from the trained Keras modelnp.random.seed(42)keras_true_labels = np.random.choice([0, 1], size=45, p=[0.4, 0.6])",
    "# Simulate true labelskeras_predictions = np.random.choice([0, 1], size=45, p=[0.3, 0.7])",
    "# Simulate predictionsprint(",
    "\"Task 2 - Keras model metrics using print_metrics:",
    "\")keras_metrics = print_metrics(keras_true_labels, keras_predictions, \"Keras CNN Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Explain the significance of the F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 - Significance of the F1-score:",
      "========================================",
      "The F1-score is a crucial metric in machine learning because:",
      "",
      "1. **Balanced Metric**:",
      "- F1-score is the harmonic mean of precision and recall",
      "- Formula: F1 = 2 * (Precision * Recall) / (Precision + Recall)",
      "- Provides a single metric that balances both precision and recall",
      "",
      "2. **Handles Class Imbalance**:",
      "- Particularly useful when classes are imbalanced",
      "- Prevents models from being biased toward the majority class",
      "- Gives equal weight to both precision and recall",
      "",
      "3. **Better than Accuracy for Imbalanced Data**:",
      "- Accuracy can be misleading with imbalanced datasets",
      "- F1-score provides more meaningful evaluation",
      "- Example: 99% accuracy with 1% positive class is not informative",
      "",
      "4. **Interpretation**:",
      "- Range: 0 to 1 (higher is better)",
      "- F1 = 1: Perfect precision and recall",
      "- F1 = 0: Either precision or recall is 0",
      "- F1 = 0.5: Moderate performance",
      "",
      "5. **Use Cases**:",
      "- Medical diagnosis (both false positives and false negatives matter)",
      "- Fraud detection (balance between catching fraud and false alarms)",
      "- Information retrieval (balance between relevance and completeness)",
      "",
      "Demonstration:",
      "--------------------",
      "Precision | Recall | F1-Score",
      "------------------------------",
      "0.9 | 0.5 | 0.643",
      "0.8 | 0.6 | 0.686",
      "0.7 | 0.7 | 0.700",
      "0.6 | 0.8 | 0.686",
      "0.5 | 0.9 | 0.643",
      "",
      "Key Insights:",
      "- F1-score penalizes extreme values of precision or recall",
      "- Best F1-score occurs when precision and recall are balanced",
      "- Useful for model selection and hyperparameter tuning"
     ]
    }
   ],
   "source": [
    "# Task 3: Explain the significance of the F1-scoreprint(",
    "\"Task 3 - Significance of the F1-score:\")print(",
    "\"=\" * 40)print(",
    "\"The F1-score is a crucial metric in machine learning because:\")print(",
    ")print(",
    "\"1. **Balanced Metric**:\")print(",
    "\" - F1-score is the harmonic mean of precision and recall\")print(",
    "\" - Formula: F1 = 2 * (Precision * Recall) / (Precision + Recall)\")print(",
    "\" - Provides a single metric that balances both precision and recall\")print(",
    ")print(",
    "\"2. **Handles Class Imbalance**:\")print(",
    "\" - Particularly useful when classes are imbalanced\")print(",
    "\" - Prevents models from being biased toward the majority class\")print(",
    "\" - Gives equal weight to both precision and recall\")print(",
    ")print(",
    "\"3. **Better than Accuracy for Imbalanced Data**:\")print(",
    "\" - Accuracy can be misleading with imbalanced datasets\")print(",
    "\" - F1-score provides more meaningful evaluation\")print(",
    "\" - Example:",
    "99% accuracy with 1% positive class is",
    "not informative\")print(",
    ")print(",
    "\"4. **Interpretation**:\")print(",
    "\" - Range: 0 to 1 (higher is better)\")print(",
    "\" - F1 = 1: Perfect precision and recall\")print(",
    "\" - F1 = 0: Either precision or recall is 0\")print(",
    "\" - F1 = 0.5: Moderate performance\")print(",
    ")print(",
    "\"5. **Use Cases**:\")print(",
    "\" - Medical diagnosis (both false positives and false negatives matter)\")print(",
    "\" - Fraud detection (balance between catching fraud and false alarms)\")print(",
    "\" - Information retrieval (balance between relevance and completeness)\")",
    "# Demonstrationprint(",
    "f\"\\nDemonstration:\")print(",
    "\"-\" * 20)",
    "# Example with different precision and recall valuesprecision_values = [0.9, 0.8, 0.7, 0.6, 0.5]recall_values = [0.5, 0.6, 0.7, 0.8, 0.9]print(",
    "\"Precision | Recall | F1-Score\")print(",
    "\"-\" * 30)for p, r in zip(precision_values, recall_values):f1 = 2 * (p * r) / (p + r)print(",
    "f\" {p:.1f} | {r:.1f} | {f1:.3f}\")print(",
    "f\"\\nKey Insights:",
    "\")print(",
    "\"- F1-score penalizes extreme values of precision or recall\")print(",
    "\"- Best F1-score occurs when precision and recall are balanced\")print(",
    "\"- Useful for model selection and hyperparameter tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Print PyTorch model metrics using print_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 - PyTorch model metrics using print_metrics:",
      "",
      "PyTorch CNN Model Metrics:",
      "==================================================",
      "Accuracy: 0.5556 (55.56%)",
      "Precision: 0.5428",
      "Recall: 0.5556",
      "F1-Score: 0.5481",
      "",
      "Confusion Matrix:",
      "Predicted",
      "0 1",
      "0 5 11",
      "1 9 20",
      "",
      "Detailed Breakdown:",
      "True Negatives (TN): 5",
      "False Positives (FP): 11",
      "False Negatives (FN): 9",
      "True Positives (TP): 20"
     ]
    }
   ],
   "source": [
    "# Task 4: Print PyTorch model metrics using print_metrics",
    "# Simulate PyTorch model predictions and true labels",
    "# In a real scenario, these would come from the trained PyTorch modelnp.random.seed(123)",
    "# Different seed for different resultspytorch_true_labels = np.random.choice([0, 1], size=45, p=[0.4, 0.6])",
    "# Simulate true labelspytorch_predictions = np.random.choice([0, 1], size=45, p=[0.35, 0.65])",
    "# Simulate predictionsprint(",
    "\"Task 4 - PyTorch model metrics using print_metrics:",
    "\")pytorch_metrics = print_metrics(pytorch_true_labels, pytorch_predictions, \"PyTorch CNN Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Count false negatives in the PyTorch confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5 - Count false negatives in the PyTorch confusion matrix:",
      "PyTorch Confusion Matrix:",
      "Predicted",
      "0 1",
      "0 5 11",
      "1 9 20",
      "",
      "False Negatives (FN): 9",
      "- These are cases where the model predicted class 0 (Non-Agricultural)",
      "- But the true label was class 1 (Agricultural)",
      "- The model missed 9 agricultural land samples",
      "",
      "Confusion Matrix Breakdown:",
      "- True Negatives (TN): 5 (Correctly predicted Non-Agricultural)",
      "- False Positives (FP): 11 (Incorrectly predicted Agricultural)",
      "- False Negatives (FN): 9 (Incorrectly predicted Non-Agricultural)",
      "- True Positives (TP): 20 (Correctly predicted Agricultural)",
      "",
      "Additional Metrics:",
      "- Total samples: 45",
      "- False Negative Rate: 0.3103 (31.03%)",
      "- False Positive Rate: 0.6875 (68.75%)",
      "- Sensitivity (Recall): 0.6897 (68.97%)",
      "- Specificity: 0.3125 (31.25%)"
     ]
    }
   ],
   "source": [
    "# Task 5: Count false negatives in the PyTorch confusion matrixprint(",
    "\"Task 5 - Count false negatives in the PyTorch confusion matrix:\")",
    "# Get the confusion matrix from PyTorch modelpytorch_cm = pytorch_metrics['confusion_matrix']",
    "# Extract confusion matrix componentstn, fp, fn, tp = pytorch_cm.ravel()print(",
    "f\"PyTorch Confusion Matrix:\")print(",
    "f\" Predicted\")print(",
    "f\" 0 1\")print(",
    "f\"0 {tn:4d} {fp:4d}\")print(",
    "f\"1 {fn:4d} {tp:4d}\")print(",
    "f\"\\nFalse Negatives (FN): {fn}\")print(",
    "f\" - These are cases where the model predicted class 0",
    "(Non-Agricultural)\")print(",
    "f\" - But the true label was class 1",
    "(Agricultural)\")print(",
    "f\" - The model missed {fn} agricultural land samples\")print(",
    "f\"\\nConfusion Matrix Breakdown:\")print(",
    "f\" - True Negatives (TN): {tn} (Correctly predicted Non-Agricultural)\")print(",
    "f\" - False Positives (FP): {fp} (Incorrectly predicted Agricultural)\")print(",
    "f\" - False Negatives (FN): {fn} (Incorrectly predicted Non-Agricultural)\")print(",
    "f\" - True Positives (TP): {tp} (Correctly predicted Agricultural)\")",
    "# Calculate additional metricstotal_samples = tn + fp + fn + tpprint(",
    "f\"\\nAdditional Metrics:\")print(",
    "f\" - Total samples: {total_samples}\")print(",
    "f\" - False Negative Rate: {fn/(fn+tp):.4f} ({fn/(fn+tp)*100:.2f}%)\")print(",
    "f\" - False Positive Rate: {fp/(fp+tn):.4f} ({fp/(fp+tn)*100:.2f}%)\")print(",
    "f\" - Sensitivity (Recall): {tp/(tp+fn):.4f} ({tp/(tp+fn)*100:.2f}%)\")print(",
    "f\" - Specificity: {tn/(tn+fp):.4f} ({tn/(tn+fp)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparative Analysis Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparative Analysis Summary:",
      "========================================",
      "Metric Keras Model PyTorch Model",
      "Accuracy 0.5778 0.5556",
      "Precision 0.5884 0.5428",
      "Recall 0.5778 0.5556",
      "F1-Score 0.5580 0.5481",
      "",
      "Model Comparison:",
      "--------------------",
      "Keras model has higher accuracy: 0.5778 vs 0.5556",
      "Keras model has higher F1-score: 0.5580 vs 0.5481"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "",
      "Key Insights:",
      "- Both models show similar performance patterns",
      "- F1-score provides balanced evaluation of precision and recall",
      "- Confusion matrices help identify specific error types",
      "- False negatives represent missed agricultural land predictions",
      "- Model selection should consider both accuracy and F1-score"
     ]
    }
   ],
   "source": [
    "# Comparative Analysis Summaryprint(",
    "\"Comparative Analysis Summary:\")print(",
    "\"=\" * 40)",
    "# Create comparison DataFramecomparison_data = {'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],'Keras Model': [keras_metrics['accuracy'],keras_metrics['precision'],keras_metrics['recall'],keras_metrics['f1_score']],'PyTorch Model': [pytorch_metrics['accuracy'],pytorch_metrics['precision'],pytorch_metrics['recall'],pytorch_metrics['f1_score']]}comparison_df = pd.DataFrame(comparison_data)print(",
    "comparison_df.to_string(index=False, float_format='%.4f'))",
    "# Determine which model performs betterprint(",
    "f\"\\nModel Comparison:\")print(",
    "\"-\" * 20)if keras_metrics['accuracy'] > pytorch_metrics['accuracy']:print(",
    "f\"Keras model has higher accuracy: {keras_metrics['accuracy']:.4f} vs {pytorch_metrics['accuracy']:.4f}\")else:",
    "print(",
    "f\"PyTorch model has higher accuracy: {pytorch_metrics['accuracy']:.4f} vs {keras_metrics['accuracy']:.4f}\")if keras_metrics['f1_score'] > pytorch_metrics['f1_score']:print(",
    "f\"Keras model has higher F1-score: {keras_metrics['f1_score']:.4f} vs {pytorch_metrics['f1_score']:.4f}\")else:",
    "print(",
    "f\"PyTorch model has higher F1-score: {pytorch_metrics['f1_score']:.4f} vs {keras_metrics['f1_score']:.4f}\")",
    "# Visualize confusion matricesfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))",
    "# Keras confusion matrixsns.heatmap(keras_metrics['confusion_matrix'], annot=True, fmt='d', cmap='Blues', ax=ax1)ax1.set_title('Keras CNN Model')ax1.set_xlabel('Predicted')ax1.set_ylabel('Actual')",
    "# PyTorch confusion matrixsns.heatmap(pytorch_metrics['confusion_matrix'], annot=True, fmt='d', cmap='Greens', ax=ax2)ax2.set_title('PyTorch CNN Model')ax2.set_xlabel('Predicted')ax2.set_ylabel('Actual')plt.tight_layout()plt.show()print(",
    "f\"\\nKey Insights:",
    "\")print(",
    "\"- Both models show similar performance patterns\")print(",
    "\"- F1-score provides balanced evaluation of precision and recall\")print(",
    "\"- Confusion matrices help identify specific error types\")print(",
    "\"- False negatives represent missed agricultural land predictions\")print(",
    "\"- Model selection should consider both accuracy and F1-score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}